{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading image_classes.json...\n",
      "Loaded image_classes.json to <class 'dict'> object\n",
      "Loading ../dataset/evidence_for_delex.json...\n",
      "Loaded ../dataset/evidence_for_delex.json to <class 'list'> object\n"
     ]
    }
   ],
   "source": [
    "from utils.json_utils import load, load_all, save\n",
    "from utils.generic_utils import read, list2dict\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import string\n",
    "\n",
    "path = \"../dataset/\"\n",
    "with open(path + \"dialogues.json\") as f:\n",
    "        dialogues = json.load(f)\n",
    "\n",
    "# **use your own image class prediction results here**\n",
    "img_classes = load('image_classes.json')\n",
    "img2class = {v: k for k, vs in img_classes.items() for v in vs}\n",
    "class2id = {k: i for i, k in enumerate(img_classes.keys())}\n",
    "        \n",
    "data = load(path + 'evidence_for_delex.json')\n",
    "data_dict = list2dict(data, 'dialogue_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slot_info(slot):\n",
    "    info = slot.split(': ')\n",
    "    return (info[0].strip(), None) if len(info) == 1 else (info[0].strip(), info[1].strip())\n",
    "\n",
    "turn_label_key = {\n",
    "    'agent': 'dialog_act',\n",
    "    'user': 'turn_label'\n",
    "}\n",
    "\n",
    "correct_value = {\n",
    "    'yes (incl. american express & mastercard)': 'yes',\n",
    "    'yes (incl. american express)': 'yes',\n",
    "    'yes (incl. nfc payments & mastercard)': 'yes',\n",
    "    'yes (incl. nfc payments & visa)': 'yes',\n",
    "    'yes (incl. visa & american express)': 'yes',\n",
    "    'yes (incl. visa & mastercard)': 'yes',\n",
    "    'cocktail': 'cocktails',\n",
    "    'modearte': 'moderate',\n",
    "    'free & paid': 'yes',\n",
    "    'desserts': 'dessert',\n",
    "    'sessert': 'dessert',\n",
    "    'free & paid': 'yes',\n",
    "    'goos': 'good',\n",
    "    'bar snacks': 'bar snack'\n",
    "}\n",
    "\n",
    "def extract_slot(slot):\n",
    "    slot_conv = {\n",
    "        'menu': 'menus',\n",
    "        'drink': 'drinks',\n",
    "        'musics': 'music',\n",
    "        'reservation': 'reservations',\n",
    "        'credit card': 'credit cards',\n",
    "        'outdoor seatings': 'outdoor seating',\n",
    "        'dining option': 'dining options',\n",
    "        'wifi': 'wi-fi'\n",
    "    }\n",
    "    slot_name, value = slot_info(slot)\n",
    "    slot_name = slot_name.lower()\n",
    "    if slot_name in slot_conv:\n",
    "        slot_name = slot_conv[slot_name]\n",
    "    if value is not None:\n",
    "        value = value.lower()\n",
    "        if value in correct_value:\n",
    "            value = correct_value[value]\n",
    "        if slot_name == 'wi-fi' and value in ('free', 'paid', 'good'):\n",
    "            value = 'yes'\n",
    "        if value.replace(' ', '') in ('dontcare', 'don\\'tcare', 'donotcare', 'doesnotcare', 'doesntcare', 'doesn\\'tcare'):\n",
    "            value = 'dontcare'\n",
    "    return slot_name, value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/ontology.json...\n",
      "Loaded ../dataset/ontology.json to <class 'dict'> object\n"
     ]
    }
   ],
   "source": [
    "slot_opts = load( path +'ontology.json')\n",
    "\n",
    "slot_name_map = {slot_name.lower(): slot_name for slot_name in slot_opts}\n",
    "\n",
    "wrong_slots = {'delivery',}\n",
    "\n",
    "telephone_matcher = re.compile('(65|65 |[+]65|[+]65 )?\\d{4} ?\\d{4}')\n",
    "\n",
    "\n",
    "def get_candidate_value(slots):\n",
    "    for slot_name, slot_info in slots.values():\n",
    "        slot_name = slot_name.lower()\n",
    "        slot_info\n",
    "\n",
    "        \n",
    "def delex_slot(transcript, slot, exclude_slots=set(), evidences={}):\n",
    "    def dist(span1, span2):\n",
    "        return min(abs(span1[0] - span2[1]), abs(span1[1] - span2[0]))\n",
    "\n",
    "    def find_and_replace(transcript, value):\n",
    "        value_padded = ' ' + value\n",
    "        transcript_padded = ' ' + transcript\n",
    "        transcript_list = []\n",
    "        replace_with = f'[{name}]'\n",
    "        last_idx = -1\n",
    "        while True:\n",
    "            if last_idx != -1:\n",
    "                if last_idx + len(value_padded) >= len(transcript_padded):\n",
    "                    break\n",
    "                to_search = transcript_padded[last_idx + len(value_padded)]\n",
    "            else:\n",
    "                to_search = transcript_padded\n",
    "            match_idx = to_search.find(value_padded)\n",
    "            if match_idx != -1:\n",
    "                if match_idx + len(value_padded) < len(transcript_padded) and transcript_padded[match_idx + len(value_padded)].isalnum():\n",
    "                    last_idx = match_idx\n",
    "                    continue\n",
    "                if last_idx != -1:\n",
    "                    match_idx += last_idx\n",
    "                transcript_list.append(transcript[:match_idx])\n",
    "                transcript_list.append(replace_with)\n",
    "                last_idx = match_idx\n",
    "            else:\n",
    "                break\n",
    "        if last_idx != -1:\n",
    "            transcript_list.append(transcript[last_idx + len(value_padded) - 1:])\n",
    "        if transcript_list:\n",
    "            return ''.join(transcript_list), True\n",
    "        return transcript, False\n",
    "\n",
    "    name, value = extract_slot(slot)\n",
    "    if name not in exclude_slots and name not in wrong_slots and value is not None:\n",
    "        if slot_opts[slot_name_map[name.lower()]]['type'] == 'yes/no':\n",
    "            transcript_lower = transcript.lower()\n",
    "            matches = list(re.finditer(f'(^| ){value}($|[.,;! ])', transcript_lower))\n",
    "            if matches:\n",
    "                keyword_idx = transcript_lower.find(name)\n",
    "                if keyword_idx == -1:\n",
    "                    for kw in slot_opts[slot_name_map[name.lower()]]['keywords']:\n",
    "                        keyword_idx = transcript_lower.find(kw)\n",
    "                        if keyword_idx != -1:\n",
    "                            keyword = kw\n",
    "                            break\n",
    "                else:\n",
    "                    keyword = name\n",
    "                if keyword_idx != -1:\n",
    "                    first_span = matches[0].span()\n",
    "                    kw_span = (keyword_idx, keyword_idx + len(keyword))\n",
    "                    min_dist = [0, dist(first_span, kw_span)]\n",
    "                    for i, match in enumerate(matches):\n",
    "                        curr_dist = dist(match.span(), kw_span)\n",
    "                        if curr_dist < min_dist[1]:\n",
    "                            min_dist = [i, curr_dist]\n",
    "                    min_span = matches[min_dist[0]].span()\n",
    "                    t_match = matches[min_dist[0]].group(0)\n",
    "                    if t_match[0].isalpha():\n",
    "                        offset_begin = 0\n",
    "                    else:\n",
    "                        offset_begin = 1\n",
    "                    if t_match[-1].isalpha():\n",
    "                        offset_end = 0\n",
    "                    else:\n",
    "                        offset_end = 1\n",
    "                    return transcript[:min_span[0] + offset_begin] + f'[{name}]' + transcript[min_span[1] - offset_end:]\n",
    "                else:\n",
    "                    transcript_list = []\n",
    "                    if matches[0].group(0)[0].isalpha():\n",
    "                        offset_begin = 0\n",
    "                    else:\n",
    "                        offset_begin = 1\n",
    "                    transcript_list.append(transcript[:matches[0].start() + offset_begin])\n",
    "                    replace_with = f'[{name}]'\n",
    "                    for i, match in enumerate(matches):\n",
    "                        transcript_list.append(replace_with)\n",
    "                        if i < len(matches) - 1:\n",
    "                            if match.group(0)[-1].isalpha():\n",
    "                                offset_end = 0\n",
    "                            else:\n",
    "                                offset_end = 1\n",
    "                            if matches[i + 1].group(0)[0].isalpha():\n",
    "                                offset_begin = 0\n",
    "                            else:\n",
    "                                offset_begin = 1\n",
    "                            transcript_list.append(transcript[match.end() - offset_end: matches[i + 1].start() + offset_begin])\n",
    "                    if matches[-1].group(0)[-1].isalpha():\n",
    "                        offset_end = 0\n",
    "                    else:\n",
    "                        offset_end = 1\n",
    "                    transcript_list.append(transcript[matches[-1].end() - offset_end:])\n",
    "                    return ''.join(transcript_list)\n",
    "            else:\n",
    "                return transcript\n",
    "        else:\n",
    "            value = slot.split(': ')[1]\n",
    "            if name == 'telephone':\n",
    "                transcipt = telephone_matcher.sub('[telephone]', transcript)\n",
    "                value = telephone_matcher.sub('[telephone]', value)\n",
    "            else:\n",
    "                result = False\n",
    "                candidates = [value, value.lower()]\n",
    "                if name in evidences:\n",
    "                    evidence = evidences[name]\n",
    "                    if evidence:\n",
    "                        if isinstance(evidence, str):\n",
    "                            evidence = [evidence]\n",
    "                        for e in evidence:\n",
    "                            if e:\n",
    "                                candidates.extend([e, e.lower()])\n",
    "                for candidate in candidates:\n",
    "                    if not result:\n",
    "                        transcript, result = find_and_replace(transcript, candidate)\n",
    "                    else:\n",
    "                        break\n",
    "            return transcript\n",
    "    return transcript\n",
    "\n",
    "\n",
    "def do_delex(dialogue, turn_idx, role='agent', exclude_slots=set()):\n",
    "    def sort_slot(sa):\n",
    "        if sa[0] == 'venueaddress':\n",
    "            return 0\n",
    "        if sa[0] == 'venuename':\n",
    "            return 1\n",
    "        return 2\n",
    "\n",
    "    dialogue_in_data = data_dict[dialogue['id']]\n",
    "    utt = dialogue['dialogue'][turn_idx][role]\n",
    "    transcript = utt['transcript']\n",
    "    if dialogue['id'] == '4131' and turn_idx == 1:\n",
    "        evidences = {}\n",
    "    elif dialogue['id'] == '4131' and turn_idx > 1:\n",
    "        utt_in_data = dialogue_in_data['dialogue'][turn_idx - 1][role]\n",
    "        evidences = {slot_name.lower(): utt_in_data['slots']['fixed'][slot_name].get('evidence', None) for slot_name in utt_in_data['slots']['fixed']}\n",
    "    elif dialogue['id'] == '4154' and turn_idx == 7:\n",
    "        evidences = {}\n",
    "    elif dialogue['id'] == '4155' and turn_idx == 9:\n",
    "        evidences = {}\n",
    "    else:\n",
    "        try:\n",
    "            utt_in_data = dialogue_in_data['dialogue'][turn_idx][role]\n",
    "        except:\n",
    "            print(dialogue['id'])\n",
    "        utt_in_data = dialogue_in_data['dialogue'][turn_idx][role]\n",
    "        evidences = {slot_name.lower(): utt_in_data['slots']['fixed'][slot_name].get('evidence', None) for slot_name in utt_in_data['slots']['fixed']}\n",
    "    slot_acts = utt[turn_label_key.get(role, 'slot-action-mapping')].items()\n",
    "    slot_acts = sorted(slot_acts, key=sort_slot)\n",
    "    for slot, act in slot_acts:\n",
    "        transcript = delex_slot(transcript, slot, exclude_slots=exclude_slots, evidences=evidences)\n",
    "    return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx_token = '<|context|>'\n",
    "ectx_token = '<|endofcontext|>'\n",
    "bst_token = '<|belief|>'\n",
    "ebst_token = '<|endofbelief|>'\n",
    "act_token = '<|action|>'\n",
    "eact_token = '<|endofaction|>'\n",
    "rsp_token = '<|response|>'\n",
    "ersp_token = '<|endofresponse|>'\n",
    "\n",
    "sys_token = '<|system|>'\n",
    "usr_token = '<|user|>'\n",
    "img_token = '<|image|>'\n",
    "imgsrc_token = '<|imagesource|>'\n",
    "\n",
    "role2token = {\n",
    "    'agent': sys_token,\n",
    "    'user': usr_token\n",
    "}\n",
    "\n",
    "multi_space_matcher = re.compile('\\s{2,}')\n",
    "\n",
    "all_slot_names = {\"drinks\", \"music\", \"reservations\", \"dining options\", \"venueaddress\", \"menus\", \"outdoor seating\",\n",
    "                  \"venueneigh\", \"wheelchair accessible\", \"smoking\", \"parking\", \"venuescore\",\n",
    "                  \"restroom\", \"venuename\", \"price\", \"telephone\", \"credit cards\", \"wi-fi\", \"open span\", \"img_gt\"}\n",
    "\n",
    "def clean(text):\n",
    "    # Remove duplicated spaces\n",
    "    text = multi_space_matcher.sub(r' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def add_space_punctuations(text):\n",
    "    for p in string.punctuation:\n",
    "        text = text.replace(p, f' {p} ')\n",
    "    return text\n",
    "\n",
    "def make_sample(dialogue,\n",
    "                turn_idx,\n",
    "                history_length=1,\n",
    "                with_context=True,\n",
    "                with_images=True,\n",
    "                with_belief=True,\n",
    "                with_action=True,\n",
    "                with_response=True,\n",
    "                delex=False,\n",
    "                sort_slots=True,\n",
    "                sort_func=None,\n",
    "                with_slot_name=True,\n",
    "                no_repetition=False,\n",
    "                accumulate_all_slots=False,\n",
    "                strict_slot_merge=False):\n",
    "    ret = []\n",
    "\n",
    "    if with_context:\n",
    "        ret.append(ctx_token)\n",
    "        ctx = make_context(dialogue, (turn_idx - history_length) if history_length > -1 else 0, turn_idx, with_images=with_images)\n",
    "        if ctx:\n",
    "            ret.append(ctx)\n",
    "        ret.append(ectx_token)\n",
    "\n",
    "    if with_belief:\n",
    "        ret.append(bst_token)\n",
    "        if accumulate_all_slots:\n",
    "            bst = []\n",
    "            for i in reversed(range(0, turn_idx)):\n",
    "                bst.append(make_bstate(dialogue['dialogue'][i]['bstate'], sort_slots=sort_slots, sort_func=sort_func))\n",
    "            bst = merge_bstate(bst, sort_slots=sort_slots, sort_func=sort_func, strict=strict_slot_merge)\n",
    "        else:\n",
    "            bst = make_bstate(dialogue['dialogue'][turn_idx - 1]['bstate'], sort_slots=sort_slots, sort_func=sort_func) if turn_idx > 0 else ''\n",
    "        if bst:\n",
    "            ret.append(bst)\n",
    "        ret.append(ebst_token)\n",
    "\n",
    "    if with_action:\n",
    "        ret.append(act_token)\n",
    "        act = make_bstate(dialogue['dialogue'][turn_idx]['agent']['dialog_act'], delex=delex, sort_slots=sort_slots, sort_func=sort_func, with_slot_name=with_slot_name, no_repetition=no_repetition)\n",
    "        if act:\n",
    "            ret.append(act)\n",
    "        ret.append(eact_token)\n",
    "\n",
    "    if with_response:\n",
    "        ret.append(rsp_token)\n",
    "        rsp = make_context(dialogue, turn_idx, turn_idx + 1, roles=['agent'], with_images=with_images, delex=delex)\n",
    "        if rsp:\n",
    "            ret.append(add_space_punctuations(rsp))\n",
    "        ret.append(ersp_token)\n",
    "    return clean(' '.join(ret)).strip()\n",
    "\n",
    "def merge_bstate(bstates_reversed, sort_slots=True, sort_func=None, strict=False):\n",
    "    curr_slot_names = set()\n",
    "    merged = []\n",
    "    for bstate in bstates_reversed:\n",
    "        if bstate:\n",
    "            slot_texts = bstate.split('; ')\n",
    "            for slot_text in slot_texts:\n",
    "                found = False\n",
    "                for slot_name in all_slot_names:\n",
    "                    if slot_text.startswith(slot_name):\n",
    "                        found = True\n",
    "                        if not strict:\n",
    "                            curr_slot_names = curr_slot_names.difference(['open span', 'img_gt'])\n",
    "                        if slot_name not in curr_slot_names:\n",
    "                            curr_slot_names.add(slot_name)\n",
    "                            if slot_text not in merged:\n",
    "                                merged.append(slot_text)\n",
    "                if found == False:\n",
    "                    print(f'1111{slot_texts}1111')\n",
    "                    print(f'1111{slot_text}1111')\n",
    "                    raise Exception()\n",
    "    if sort_slots:\n",
    "        if sort_func is None:\n",
    "            merged.sort()\n",
    "        else:\n",
    "            merged.sort(key=lambda x: sort_func(x))\n",
    "    return ' ; '.join(merged)\n",
    "\n",
    "def make_slot_comps(name, value, act, delex=False, with_slot_name=True):\n",
    "    if value is not None:\n",
    "        value = add_space_punctuations(value)\n",
    "    slot_comps = [name, value, act]\n",
    "    if delex:\n",
    "        slot_comps[1] = None\n",
    "    if not with_slot_name:\n",
    "        slot_comps[0] = None\n",
    "    return [(x.strip() if x is not None else '') for x in slot_comps]\n",
    "\n",
    "def make_bstate(bstate, with_images=True, delex=False, sort_slots=True, sort_func=None, with_slot_name=True, no_repetition=False):\n",
    "    all_slots = []\n",
    "    for slot, act in bstate.items():\n",
    "        slot = slot.replace('：', ':').replace('；', ':').replace(':', ': ').replace('  ', ' ')\n",
    "        name, value = extract_slot(slot)\n",
    "        if name in wrong_slots:\n",
    "            continue\n",
    "        if with_images or name != 'img_gts':\n",
    "            if name == 'img_gts':\n",
    "                name = 'img_gt'\n",
    "                for v in value.split(', '):\n",
    "                    all_slots.append(make_slot_comps(name, v, act, delex=delex, with_slot_name=with_slot_name))\n",
    "            else:\n",
    "                all_slots.append(make_slot_comps(name, value, act, delex=delex, with_slot_name=with_slot_name))\n",
    "    if sort_slots:\n",
    "        if sort_func is None:\n",
    "            all_slots.sort()\n",
    "        else:\n",
    "            all_slots.sort(key=lambda x: sort_func(x))\n",
    "    ret = [' '.join(x) for x in all_slots]\n",
    "    if no_repetition:\n",
    "        ret_set = set()\n",
    "        new_ret = []\n",
    "        for r in ret:\n",
    "            if r not in ret_set:\n",
    "                ret_set.add(r)\n",
    "                new_ret.append(r)\n",
    "        ret = new_ret\n",
    "    return clean(' ; '.join(ret))\n",
    "\n",
    "def make_context(dialogue, lower, upper, reverse=False, roles=('agent', 'user'), with_images=True, delex=False):\n",
    "    r = range(max(0, lower), min(len(dialogue['dialogue']), upper))\n",
    "    if reverse:\n",
    "        r = reverse(r)\n",
    "    ctx = []\n",
    "    for i in r:\n",
    "        for role in roles:\n",
    "            role_token = role2token[role]\n",
    "            if delex:\n",
    "                transcript = do_delex(dialogue, i, role=role, exclude_slots={'open span', 'img_gts', 'openspan', 'open psan', 'opne span', 'open open', 'opan span', 'open sapn', 'delivery', 'open span:', 'oprn span', 'openn span', 'open spicy', 'opens span', 'open spam', 'oepn span'})\n",
    "            else:\n",
    "                transcript = dialogue['dialogue'][i][role]['transcript']\n",
    "            images = ''\n",
    "            image_sources = ''\n",
    "            if with_images:\n",
    "                turn_label = dialogue['dialogue'][i][role][turn_label_key.get(role, 'slot-action-mapping')]\n",
    "                for slot, act in turn_label.items():\n",
    "                    name, value = extract_slot(slot)\n",
    "                    if name in wrong_slots:\n",
    "                        continue\n",
    "                    if name == 'img_gts':\n",
    "                        images = ', '.join( [img2class[img] for img in dialogue['dialogue'][i][role]['imgs']] )\n",
    "                        image_sources = ', '.join(dialogue['dialogue'][i][role]['imgs'])\n",
    "                        break\n",
    "            if transcript or images:\n",
    "                ctx.append(role_token)\n",
    "                if transcript:\n",
    "                    ctx.append(add_space_punctuations(transcript))\n",
    "                if images:\n",
    "                    ctx.append(img_token)\n",
    "                    ctx.append(add_space_punctuations(images))\n",
    "                #if image_sources:\n",
    "                    #ctx.append(imgsrc_token)\n",
    "                    #ctx.append(image_sources)\n",
    "    return clean(' '.join(ctx).replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/data_split.json...\n",
      "Loaded ../dataset/data_split.json to <class 'dict'> object\n",
      "train: 3500 dialogues\n",
      "val: 606 dialogues\n",
      "test: 1000 dialogues\n"
     ]
    }
   ],
   "source": [
    "splits = load(path + 'data_split.json')\n",
    "for split_name, split in splits.items():\n",
    "    print(f'{split_name}: {len(split)} dialogues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def prepare_path(path):\n",
    "    folder, file = os.path.split(path)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\n",
    "input_formats = {\n",
    "    'dst': {\n",
    "        'history_length': -1,\n",
    "        'with_context': True,\n",
    "        'with_images': True,\n",
    "        'with_belief': True,\n",
    "        'with_action': False,\n",
    "        'with_response': False,\n",
    "        'delex': False,\n",
    "        'sort_slots': True,\n",
    "        'sort_func': None,\n",
    "        'with_slot_name': True,\n",
    "        'no_repetition': False,\n",
    "        'accumulate_all_slots': True,\n",
    "        'strict_slot_merge': False\n",
    "    },\n",
    "    'act_pred': {\n",
    "        'history_length': -1,\n",
    "        'with_context': True,\n",
    "        'with_images': True,\n",
    "        'with_belief': True,\n",
    "        'with_action': True,\n",
    "        'with_response': False,\n",
    "        'delex': False,\n",
    "        'sort_slots': True,\n",
    "        'sort_func': None,\n",
    "        'with_slot_name': True,\n",
    "        'no_repetition': False,\n",
    "        'accumulate_all_slots': False,\n",
    "        'strict_slot_merge': False\n",
    "    }\n",
    "}\n",
    "\n",
    "output_format = \"dst\"\n",
    "\n",
    "for split_name, split in splits.items():\n",
    "    output = f'resources/{split_name}.{output_format}'\n",
    "    prepare_path(output)\n",
    "    with open(output, 'w+') as f:\n",
    "        for id_ in split:\n",
    "            dialogue = dialogues[id_]\n",
    "            for i in range(1, len(dialogue['dialogue'])):\n",
    "                sample = make_sample(dialogue, i, **input_formats[output_format])\n",
    "                f.write(f'{sample}\\n')\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving <class 'dict'> object to resources/slot_values.json...\n",
      "Saved <class 'dict'> object to resources/slot_values.json\n"
     ]
    }
   ],
   "source": [
    "slot_names = {'wheelchair accessible', 'reservations', 'restroom', 'smoking', 'credit cards', 'outdoor seating', 'parking', 'music', 'wi-fi', 'dining options', 'drinks', 'venuescore', 'menus', 'price', 'venueneigh', 'venuename', 'telephone', 'venueaddress', 'img_gt', 'open span'}\n",
    "\n",
    "slot_values = defaultdict(set)\n",
    "\n",
    "token_matcher = re.compile(r'<\\|[a-zA-Z]+\\|>')\n",
    "\n",
    "def extract(text, begin_token, end_token=None, no_token_in_between=True):\n",
    "    end_token = end_token or f'<|endof{get_token_text(begin_token)}|>'\n",
    "    begin_idx = text.find(begin_token)\n",
    "    if begin_idx == -1:\n",
    "        return '', None\n",
    "    begin_with_len = begin_idx + len(begin_token)\n",
    "    end_idx = text[begin_with_len:].find(end_token)\n",
    "    if end_idx == -1:\n",
    "        return '', None\n",
    "    end_idx += begin_with_len\n",
    "    next_token_ = next_token(text[begin_with_len:])\n",
    "    if not no_token_in_between or next_token_ == end_token:\n",
    "        return text[begin_with_len: end_idx].strip(), begin_idx\n",
    "    recurse_result = extract(text[begin_with_len:], begin_token, end_token=end_token, no_token_in_between=no_token_in_between)\n",
    "    return recurse_result[0], (recurse_result[1] + begin_with_len) if recurse_result[1] is not None else None\n",
    "\n",
    "def has_token(text):\n",
    "    return next_token(text) is not None\n",
    "\n",
    "def next_token(text):\n",
    "    result = token_matcher.search(text)\n",
    "    return result if result is None else result[0]\n",
    "\n",
    "\n",
    "def get_token_text(token):\n",
    "    return token.replace('<', '').replace('>', '').replace('|', '').replace('[', '').replace(']', '')\n",
    "\n",
    "input_format = 'dst'\n",
    "for split in ['train', 'test', 'val']:\n",
    "    data = read(f'resources/{split}.{input_format}')\n",
    "    for sample in data:\n",
    "        belief = extract(sample, '<|belief|>')[0]\n",
    "        if belief:\n",
    "            for slot in belief.split('; '):\n",
    "                slot_split = slot.split()\n",
    "                action = slot_split[-1]\n",
    "                slot_name = slot_split[0] if slot_split[0] in slot_names else ' '.join(slot_split[:2])\n",
    "                assert slot_name in slot_names\n",
    "                value = ' '.join(slot_split[len(slot_name.split()): -1])\n",
    "                if not value:\n",
    "                    value = None\n",
    "                if value is not None:\n",
    "                    slot_values[slot_name].add(value)\n",
    "\n",
    "slot_values_sorted = {}\n",
    "for k in sorted(slot_values.keys()):\n",
    "    slot_values_sorted[k] = sorted(slot_values[k])\n",
    "save(slot_values_sorted, 'resources/slot_values.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
